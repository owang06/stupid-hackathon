<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ScreamStream - Voice-Controlled YouTube Volume</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://www.youtube.com/iframe_api"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&display=swap');
        
        * {
            font-family: 'Inter', sans-serif;
        }

        #pitchVisualizer {
            border-radius: 12px;
        }

        #facecam {
            border-radius: 12px;
            box-shadow: 0 10px 40px rgba(76, 175, 80, 0.3);
        }

        body{
            transform: scale(0.9); /* 0.9 = 90% of original size */
            transform-origin: top left; /* keep layout anchored */
            align-items: center;
        }

        /* Custom slider styling */
        input[type="range"] {
            -webkit-appearance: none;
            appearance: none;
            background: transparent;
            cursor: pointer;
        }

        input[type="range"]::-webkit-slider-track {
            background: linear-gradient(to right, #10b981, #f59e0b, #ef4444);
            height: 8px;
            border-radius: 4px;
        }

        input[type="range"]::-webkit-slider-thumb {
            -webkit-appearance: none;
            appearance: none;
            background: white;
            height: 20px;
            width: 20px;
            border-radius: 50%;
            box-shadow: 0 2px 6px rgba(0, 0, 0, 0.3);
            border: 2px solid #10b981;
        }

        input[type="range"]::-moz-range-track {
            background: linear-gradient(to right, #10b981, #f59e0b, #ef4444);
            height: 8px;
            border-radius: 4px;
        }

        input[type="range"]::-moz-range-thumb {
            background: white;
            height: 20px;
            width: 20px;
            border-radius: 50%;
            box-shadow: 0 2px 6px rgba(0, 0, 0, 0.3);
            border: 2px solid #10b981;
            cursor: pointer;
        }

        .gradient-text {
            background: linear-gradient(135deg, #10b981 0%, #3b82f6 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
    </style>
</head>
<body class="min-h-screen bg-gradient-to-br from-gray-900 via-gray-800 to-gray-900 text-white overflow-x-hidden">
    <div class="container mx-auto px-4 py-4 max-w-7xl">
        <!-- Compact Header -->
        <div class="text-center mb-4">
            <h1 class="text-4xl font-bold gradient-text mb-1">ScreamStream</h1>
            <p class="text-gray-400 text-sm">Control YouTube volume with your voice</p>
        </div>

        <!-- Main Content - Side by Side Layout -->
        <div class="grid grid-cols-[850px_300px] gap-4">
            <!-- Left: YouTube Player -->
            <div class="bg-gray-800/50 backdrop-blur-sm rounded-2xl p-4 shadow-2xl border border-gray-700/50">
                <div class="relative rounded-xl overflow-hidden shadow-2xl" style="width: 100%; height: 619px;">
                    <iframe id="youtubeFrame" 
                            class="w-full h-full"
                            src="https://www.youtube.com/embed/Oo9EbArcQ1c?enablejsapi=1&controls=1&rel=0&modestbranding=1&origin=http://localhost:8000"
                            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                            allowfullscreen>
                    </iframe>
                </div>
            </div>

            <!-- Right: Facecam on top, Vertical Loudness Spectrum below -->
            <div class="space-y-4">
                <!-- Facecam Card -->
                <div class="bg-gray-800/50 backdrop-blur-sm rounded-2xl p-4 shadow-2xl border border-gray-700/50">
                    <h2 class="text-sm font-semibold mb-2 flex items-center gap-2">
                        <span class="w-2 h-2 bg-blue-400 rounded-full animate-pulse"></span>
                        Live Camera
                    </h2>
                    <div class="relative rounded-xl overflow-hidden bg-black">
                        <video id="facecam" 
                               autoplay 
                               playsinline 
                               muted
                               class="w-full h-[180px] object-cover border-2 border-green-400/50">
                        </video>
                        <div class="absolute top-2 right-2 bg-red-500 rounded-full w-2 h-2 animate-pulse"></div>
                    </div>
                </div>

                <!-- Vertical Loudness Spectrum Card -->
                <div class="bg-gray-800/50 backdrop-blur-sm rounded-2xl p-4 shadow-2xl border border-gray-700/50 flex-1">
                    <h2 class="text-sm font-semibold mb-2 flex items-center gap-2">
                        <span class="w-2 h-2 bg-green-400 rounded-full animate-pulse"></span>
                        Loudness
                    </h2>
                    
                    <div class="bg-black/50 rounded-xl p-3 mb-3 flex justify-center items-center" style="height: 400px;">
                        <canvas id="pitchVisualizer" width="200" height="400" class="rounded-lg"></canvas>
                    </div>

                    <!-- Sensitivity Control - Compact -->
                    <div class="bg-gray-700/30 rounded-xl p-3 mb-3">
                        <label for="sensitivitySlider" class="block text-xs font-medium text-gray-300 mb-2">
                            Sensitivity
                        </label>
                        <div class="flex flex-col items-center gap-2">
                            <div class="flex items-center justify-between w-full text-xs text-gray-400 mb-1">
                                <span>Low</span>
                                <span class="text-lg font-bold text-green-400" id="sensitivityValue">5.0</span>
                                <span>High</span>
                            </div>
                            <input type="range" 
                                   id="sensitivitySlider" 
                                   min="1" 
                                   max="10" 
                                   value="5" 
                                   step="0.5"
                                   class="w-full">
                        </div>
                    </div>

                    <!-- Head Tilt Control Status -->
                    <div class="bg-gray-700/30 rounded-xl p-3 mb-3">
                        <div class="text-xs font-semibold text-gray-300 mb-2">Head Tilt Control</div>
                        <div id="headTiltStatus" class="text-center text-xs text-gray-400 mt-1">
                            Tilt head left/right to control video
                        </div>
                        <div class="text-center text-xs text-gray-500 mt-2">
                            Left = ‚è™ Back 10s | Right = ‚è© Forward 10s
                        </div>
                    </div>

                    <!-- Status - Compact -->
                    <div class="bg-gray-700/30 rounded-xl p-2">
                        <div id="status" class="text-center text-xs text-gray-300">
                            Requesting microphone access...
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script>
        let audioContext;
        let analyser;
        let microphone;
        let mediaStream;
        let dataArray;
        let timeDataArray;
        let bufferLength;
        let animationFrame;
        let pitchVisualizerCanvas;
        let pitchVisualizerCtx;
        let sensitivity = 5.0;
        let smoothedVolume = 0;
        const smoothingFactor = 0.85;
        
        // Tongue control variables
        let tongueWebSocket = null;
        let lastTongueAction = null;
        let tongueActionCooldown = 1000; // 1 second cooldown between actions
        let lastTongueActionTime = 0;
        let youtubePlayer = null;

        // Initialize YouTube IFrame API
        function onYouTubeIframeAPIReady() {
            console.log('‚úÖ YouTube IFrame API ready');
            youtubePlayerReady = true;
            
            // Create player instance if needed
            const iframe = document.getElementById('youtubeFrame');
            if (iframe) {
                youtubePlayer = iframe;
                console.log('YouTube iframe ready');
            }
        }

        // Track current video time (updated from YouTube messages)
        let currentVideoTime = 0;
        let isPlaying = false; // Track play/pause state locally
        let youtubePlayerReady = false;
        let lastSeekTime = Date.now(); // Track when we last sought to estimate current time
        
        // Estimate current time if not tracked (for relative seeking)
        function getEstimatedCurrentTime() {
            if (currentVideoTime > 0) {
                // Use tracked time if available
                return currentVideoTime;
            }
            // Fallback: estimate based on last seek time
            // This is a workaround - not perfect but better than 0
            const timeSinceSeek = (Date.now() - lastSeekTime) / 1000;
            return Math.max(0, currentVideoTime + timeSinceSeek);
        }
        
        // Listen for YouTube player messages to track state
        window.addEventListener('message', (event) => {
            if (event.origin !== 'https://www.youtube.com') return;
            try {
                const data = typeof event.data === 'string' ? JSON.parse(event.data) : event.data;
                
                // YouTube sends info updates
                if (data.info) {
                    if (data.info.currentTime !== undefined) {
                        currentVideoTime = data.info.currentTime;
                        lastSeekTime = Date.now();
                    }
                    if (data.info.playerState !== undefined) {
                        isPlaying = (data.info.playerState === 1);
                    }
                }
                
                // Also check for direct property access
                if (data.currentTime !== undefined) {
                    currentVideoTime = data.currentTime;
                    lastSeekTime = Date.now();
                }
                if (data.playerState !== undefined) {
                    isPlaying = (data.playerState === 1);
                }
                
                // Mark player as ready when we get any message
                if (!youtubePlayerReady) {
                    youtubePlayerReady = true;
                    console.log('‚úÖ YouTube player ready');
                }
            } catch (e) {
                // Not a JSON message, ignore
            }
        });
        
        // Request player state periodically to track time for relative seeking
        setInterval(() => {
            const iframe = document.getElementById('youtubeFrame');
            if (iframe && iframe.contentWindow && youtubePlayerReady) {
                try {
                    // Request current time to keep currentVideoTime updated
                    iframe.contentWindow.postMessage(JSON.stringify({
                        event: 'command',
                        func: 'getCurrentTime'
                    }), 'https://www.youtube.com');
                } catch (e) {
                    // Ignore errors
                }
            }
        }, 500); // Request every 500ms to keep time tracking accurate

        // Function to seek forward 10 seconds (like L key)
        function seekForward() {
            const iframe = document.getElementById('youtubeFrame');
            if (!iframe || !iframe.contentWindow) {
                console.warn('‚ö†Ô∏è YouTube iframe not found');
                return;
            }
            
            // Get estimated current time (tracks from YouTube messages or estimates)
            let timeToUse = getEstimatedCurrentTime();
            const newTime = timeToUse + 10;
            
            // Update tracked time for next operation
            currentVideoTime = newTime;
            lastSeekTime = Date.now();
            
            // Seek to new time (relative forward 10 seconds)
            iframe.contentWindow.postMessage(JSON.stringify({
                event: 'command',
                func: 'seekTo',
                args: [Math.floor(newTime), true]
            }), 'https://www.youtube.com');
            
            console.log(`‚è© Forward 10s (relative, like L key: ${timeToUse.toFixed(1)}s ‚Üí ${newTime.toFixed(1)}s)`);
        }

        // Function to seek backward 10 seconds (like J key)
        function seekBackward() {
            const iframe = document.getElementById('youtubeFrame');
            if (!iframe || !iframe.contentWindow) {
                console.warn('‚ö†Ô∏è YouTube iframe not found');
                return;
            }
            
            // Get estimated current time
            let timeToUse = getEstimatedCurrentTime();
            
            if (timeToUse <= 0) {
                console.log('‚è™ Already at start, cannot go back further');
                return;
            }
            
            const newTime = Math.max(0, timeToUse - 10);
            
            // Update tracked time for next operation
            currentVideoTime = newTime;
            lastSeekTime = Date.now();
            
            // Seek to new time (relative backward 10 seconds)
            iframe.contentWindow.postMessage(JSON.stringify({
                event: 'command',
                func: 'seekTo',
                args: [Math.floor(newTime), true]
            }), 'https://www.youtube.com');
            
            console.log(`‚è™ Backward 10s (relative, like J key: ${timeToUse.toFixed(1)}s ‚Üí ${newTime.toFixed(1)}s)`);
        }

        // Toggle play/pause based on tracked state
        function togglePlayPause() {
            const iframe = document.getElementById('youtubeFrame');
            if (!iframe || !iframe.contentWindow) {
                console.warn('‚ö†Ô∏è YouTube iframe not found');
                return;
            }
            
            // Try to get player state first, then toggle
            const command = JSON.stringify({
                event: 'command',
                func: isPlaying ? 'pauseVideo' : 'playVideo'
            });
            
            // Send with explicit origin
            iframe.contentWindow.postMessage(command, 'https://www.youtube.com');
            
            // Toggle our local state
            isPlaying = !isPlaying;
            console.log(`‚èØÔ∏è ${isPlaying ? 'Playing' : 'Paused'} (toggled)`);
        }

        // Initialize WebSocket connection for tongue control
        function initTongueWebSocket() {
            const wsUrl = 'ws://localhost:8765';
            
            try {
                tongueWebSocket = new WebSocket(wsUrl);
                
                tongueWebSocket.onopen = () => {
                    console.log('‚úÖ Connected to head tilt detection server');
                    updateStatus('Head tilt control: Connected');
                    const headTiltStatus = document.getElementById('headTiltStatus');
                    if (headTiltStatus) {
                        headTiltStatus.textContent = '‚úÖ Connected - Tilt head to control video';
                        headTiltStatus.className = 'text-center text-xs text-green-400 mt-1';
                    }
                };
                
                tongueWebSocket.onmessage = (event) => {
                    try {
                        const data = JSON.parse(event.data);
                        const headTilt = data.head_tilt;
                        
                        if (!headTilt) return;
                        
                        // Only control video - no display updates
                        const currentTime = Date.now();
                        
                        // Control video only if position changed AND cooldown expired (prevent spam)
                        if (headTilt !== lastTongueAction) {
                            if (currentTime - lastTongueActionTime >= tongueActionCooldown) {
                                lastTongueAction = headTilt;
                                lastTongueActionTime = currentTime;
                                
                                console.log(`üë§ Head tilt: ${headTilt} ‚Üí Controlling video`);
                                
                                // Control YouTube based on head tilt
                                if (headTilt === 'right') {
                                    seekForward();  // Tilt right = skip forward 10s (like L key)
                                    console.log(`‚è© Skipping forward 10 seconds`);
                                } else if (headTilt === 'left') {
                                    seekBackward();  // Tilt left = skip backward 10s (like J key)
                                    console.log(`‚è™ Skipping backward 10 seconds`);
                                }
                                // 'center' does nothing
                            }
                        }
                    } catch (error) {
                        console.error('Error parsing head tilt data:', error);
                        console.error('Raw data:', event.data);
                    }
                };
                
                tongueWebSocket.onerror = (error) => {
                    console.warn('‚ö†Ô∏è Head tilt WebSocket error (is tongue_detection_simple.py running?):', error);
                };
                
                tongueWebSocket.onclose = () => {
                    console.log('‚ùå Head tilt WebSocket closed. Reconnecting...');
                    updateStatus('Head tilt control: Disconnected');
                    const headTiltStatus = document.getElementById('headTiltStatus');
                    if (headTiltStatus) {
                        headTiltStatus.textContent = '‚ùå Disconnected - Reconnecting...';
                        headTiltStatus.className = 'text-center text-xs text-red-400 mt-1';
                    }
                    // Reconnect after 3 seconds
                    setTimeout(initTongueWebSocket, 3000);
                };
            } catch (error) {
                console.warn('Could not connect to tongue detection server:', error);
            }
        }

        // Function to update status message
        function updateStatus(message) {
            const statusEl = document.getElementById('status');
            if (statusEl) {
                const currentStatus = statusEl.textContent;
                if (currentStatus && !currentStatus.includes('Tongue control')) {
                    statusEl.innerHTML = `<div>${currentStatus}</div><div class="text-xs mt-1 text-blue-400">${message}</div>`;
                }
            }
        }

        // Function to update YouTube volume via iframe postMessage
        function updateYouTubeVolume(volume) {
            const iframe = document.getElementById('youtubeFrame');
            if (iframe && iframe.contentWindow) {
                try {
                    iframe.contentWindow.postMessage(JSON.stringify({
                        event: 'command',
                        func: 'setVolume',
                        args: [volume]
                    }), '*');
                } catch (error) {
                    console.log('Could not set volume via postMessage');
                }
            }
        }

        async function initAudio() {
            try {
                console.log('Requesting microphone and camera access...');
                mediaStream = await navigator.mediaDevices.getUserMedia({ 
                    audio: true, 
                    video: { 
                        width: 250, 
                        height: 188,
                        facingMode: 'user'
                    } 
                });
                
                console.log('Microphone and camera access granted!');
                
                const facecam = document.getElementById('facecam');
                if (facecam && mediaStream) {
                    facecam.srcObject = mediaStream;
                    console.log('Facecam started');
                }
                
                const statusEl = document.getElementById('status');
                statusEl.innerHTML = '<span class="text-green-400">‚úì Microphone and camera active - Loudness controls volume</span>';

                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                microphone = audioContext.createMediaStreamSource(mediaStream);

                analyser.fftSize = 4096;
                analyser.smoothingTimeConstant = 0.3;
                bufferLength = analyser.frequencyBinCount;
                dataArray = new Uint8Array(bufferLength);
                timeDataArray = new Float32Array(analyser.fftSize);

                microphone.connect(analyser);

                pitchVisualizerCanvas = document.getElementById('pitchVisualizer');
                pitchVisualizerCtx = pitchVisualizerCanvas.getContext('2d');

                detectVolume();

            } catch (error) {
                console.error('Error accessing microphone:', error);
                const statusEl = document.getElementById('status');
                statusEl.innerHTML = `<span class="text-red-400">‚úó Error: ${error.message}</span>`;
            }
        }

        function detectVolume() {
            function update() {
                if (!audioContext) return;
                
                animationFrame = requestAnimationFrame(update);

                analyser.getFloatTimeDomainData(timeDataArray);

                let sum = 0;
                for (let i = 0; i < timeDataArray.length; i++) {
                    const normalized = timeDataArray[i];
                    sum += normalized * normalized;
                }
                const rms = Math.sqrt(sum / timeDataArray.length);

                let volume = 0;
                if (rms > 0.001) {
                    const sensitivityMultiplier = sensitivity / 5.0;
                    const adjustedRms = Math.min(0.3, rms * sensitivityMultiplier);
                    const exponent = 0.6 - (sensitivity / 10.0 * 0.3);
                    const normalizedRms = adjustedRms / 0.3;
                    volume = Math.min(100, Math.round(Math.pow(normalizedRms, exponent) * 100));
                }

                smoothedVolume = smoothedVolume * smoothingFactor + volume * (1 - smoothingFactor);
                const finalVolume = Math.round(smoothedVolume);

                updateYouTubeVolume(finalVolume);
                drawLoudnessVisualizer(finalVolume);
            }

            update();
        }

        function drawLoudnessVisualizer(volumePercent) {
            const canvas = pitchVisualizerCanvas;
            const ctx = pitchVisualizerCtx;
            const width = canvas.width;
            const height = canvas.height;

            ctx.fillStyle = '#0a0a0a';
            ctx.fillRect(0, 0, width, height);

            const position = volumePercent / 100;

            // Vertical bar - centered horizontally
            const barWidth = 60;
            const barX = (width - barWidth) / 2;
            const barMargin = 30;
            const barHeight = height - (barMargin * 2);
            
            // Draw background bar
            ctx.fillStyle = '#1f2937';
            ctx.fillRect(barX, barMargin, barWidth, barHeight);

            // Calculate fill height from bottom (0% at bottom, 100% at top)
            const fillHeight = barHeight * position;
            
            // Vertical gradient (green at bottom to red at top)
            const gradient = ctx.createLinearGradient(barX, barMargin + barHeight, barX, barMargin);
            gradient.addColorStop(0, '#10b981'); // Green - quiet (bottom)
            gradient.addColorStop(0.5, '#f59e0b'); // Yellow - medium
            gradient.addColorStop(1, '#ef4444'); // Red - loud (top)
            
            ctx.fillStyle = gradient;
            ctx.fillRect(barX, barMargin + barHeight - fillHeight, barWidth, fillHeight);

            // Draw border
            ctx.strokeStyle = '#374151';
            ctx.lineWidth = 2;
            ctx.strokeRect(barX, barMargin, barWidth, barHeight);

            // Draw indicator line (horizontal line at current volume level)
            const indicatorY = barMargin + barHeight - fillHeight;
            ctx.fillStyle = volumePercent > 0 ? '#ffffff' : '#6b7280';
            ctx.fillRect(barX - 8, indicatorY - 2, barWidth + 16, 4);

            // Draw volume label next to indicator
            ctx.save();
            ctx.fillStyle = volumePercent > 0 ? '#ffffff' : '#9ca3af';
            ctx.font = 'bold 14px Inter, sans-serif';
            ctx.textAlign = 'center';
            ctx.fillText(`${volumePercent}%`, width / 2, indicatorY - 8);
            ctx.restore();

            // Draw labels at top and bottom
            ctx.fillStyle = '#9ca3af';
            ctx.font = '12px Inter, sans-serif';
            ctx.textAlign = 'center';
            ctx.fillText('Loud (100%)', width / 2, barMargin - 10);
            ctx.fillText('Quiet (0%)', width / 2, height - barMargin + 15);
        }

        function cleanup() {
            if (animationFrame) {
                cancelAnimationFrame(animationFrame);
            }
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
            }
            if (audioContext && audioContext.state !== 'closed') {
                audioContext.close();
            }
        }

        function initSlider() {
            const sensitivitySlider = document.getElementById('sensitivitySlider');
            const sensitivityValue = document.getElementById('sensitivityValue');
            
            if (sensitivitySlider && sensitivityValue) {
                sensitivitySlider.addEventListener('input', (e) => {
                    sensitivity = parseFloat(e.target.value);
                    sensitivityValue.textContent = sensitivity.toFixed(1);
                });
                
                sensitivitySlider.addEventListener('change', (e) => {
                    sensitivity = parseFloat(e.target.value);
                    sensitivityValue.textContent = sensitivity.toFixed(1);
                });
            }
        }

        if (document.readyState === 'loading') {
            document.addEventListener('DOMContentLoaded', initSlider);
        } else {
            initSlider();
        }

        initAudio();
        
        // Initialize tongue control WebSocket
        // Wait a bit for page to load before connecting
        setTimeout(() => {
            initTongueWebSocket();
        }, 1000);
        
        window.addEventListener('beforeunload', cleanup);
        
        // Cleanup WebSocket on page unload
        window.addEventListener('beforeunload', () => {
            if (tongueWebSocket) {
                tongueWebSocket.close();
            }
        });
    </script>
</body>
</html>